# 1. FC-Layer (ì™„ì „ì—°ê²°ì¸µ, Fully-Connected Layer)

![dense](https://user-images.githubusercontent.com/87812424/136775670-da1505ae-dd4f-4b87-9f1d-0a657b54e220.png)

*  í•œì¸µì˜ ëª¨ë“  ë‰´ëŸ°ì´ ë‹¤ìŒì¸µì˜ ëª¨ë“  ë‰´ëŸ°ê³¼ ì—°ê²°ëœ ìƒíƒœ
*  outputì˜ ê° elementë¥¼ ìƒì„±í•˜ëŠ”ë° ëª¨ë“  inputì´ ì‚¬ìš©ëœë‹¤ í•˜ì—¬ ì™„ì „ì—°ê²°ì¸µì´ë¼ ì´ë¦„ì´ ë¶™ìŒ
*  Y = f(W * X + b ) <br/> (X: input data, W: weight, b: bais, Y: output data, f: activation func)
*  íŒŒë¼ë¯¸í„° ê°œìˆ˜: inputê°œìˆ˜ x outputê°œìˆ˜ + outputê°œìˆ˜(bais)

ì•„ë˜ëŠ” ê°„ë‹¨í•œ Keras Dense ì‚¬ìš© ì˜ˆì‹œì´ë©°, <br/>
5ê°œì˜ input ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ 1ê°œì˜ ì •ë‹µì„ ì¶”ì¶œí•˜ëŠ” ì½”ë“œì´ë‹¤.<br/>
(ex. ê³¼ê±° ì†ë„ 5ê°œë¡œ ë¯¸ë˜ ì†ë„ 1ê°œ ì˜ˆì¸¡)<br/>
<pre>
<code>
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

input = layers.Input(shape=(5, )) # input ê°œìˆ˜: 5ê°œ
hidden = layers.Dense(32, activation="relu")(input) # output ê°œìˆ˜: 32ê°œ -> Units ê°œìˆ˜
output = layers.Dense(1)(hidden) # output ê°œìˆ˜: 1ê°œ -> Units ê°œìˆ˜

model = keras.Model(inputs=input, outputs=output)
</code>
</pre>




</br></br>
# 2. CNN (í•©ì„±ê³±ì‹ ê²½ë§, Convolution Neural Network)

* Convolutionì€ ì´ë¯¸ì§€ ë¶„ì„ì— í° ì„±ê³¼ë¥¼ ì´ë¤„ëƒˆë‹¤.
* ì´ë¯¸ì§€ëŠ” (H, W, C) 3ì°¨ì› Shapeìœ¼ë¡œ CëŠ” RGBë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.
* ì´ë¯¸ì§€ë¥¼ ì™„ì „ì—°ê²°(FC, Dense) ëª¨ë¸ë¡œ í•™ìŠµ í•  ê²½ìš° <br/> a. ë°ì´í„°ê°€ 1ì°¨ì›ì´ì–´ì•¼ í•œë‹¤. <br/> b. ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì¼ìˆ˜ë¡ íŒŒë¼ë¯¸í„° ê°œìˆ˜ê°€ ê¸‰ì¦í•œë‹¤. (H x W x C) x (outputê°œìˆ˜) <br/> c. ë˜í•œ ì§ë ¬í™”ë¡œ ì¸í•´ ë°ì´í„°ì˜ ê³µê°„ì  í˜•ìƒì´ ë¬´ì‹œëœë‹¤.

CNNì€ ìœ„ì™€ ê°™ì€ ë‹¨ì ì„ ë³´ì™„í•˜ë©´ì„œ ì´ë¯¸ì§€ ë¶„ì„ì„ íš¨ìœ¨ì ìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ë‹¤.

<img src="https://user-images.githubusercontent.com/87812424/136781126-ffabc83e-1441-43e8-a305-1734df428cc6.png" width="50%" height="50%"/>

CNNì€ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ Kernelì´ë¼ëŠ” shared weightë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, Kernelì´ ì´ë™í•˜ë©´ì„œ Feature mapì´ í•˜ë‚˜ì”© ì±„ì›Œì§„ë‹¤.
(Kernelì€ 1ê°œ Chennelì— ëŒ€í•´ì„œë§Œ ê³µìœ ëœë‹¤. filter(output chennel)ê°œìˆ˜ê°€ 10ê°œë¼ë©´ kernelì€ 10ê°œ ì¡´ì¬í•œë‹¤.)
ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
* ì´ë¯¸ì§€ëŠ” ì¸ì ‘í•œ ê³µê°„ì— ëŒ€í•œ ì—°ê´€ì„±ì„ ê°€ì§€ ë°ì´í„°ì´ë‹¤.
* ì´ëŸ¬í•œ ê³µê°„ì  ì—°ê´€ì„±ì„ Kernelì´ë€ Weightë¥¼ í†µí•´ strideë§Œí¼ ì´ë™í•˜ë©° ë¶„ì„í•œë‹¤.
* ì™„ì „ì—°ê²°ì´ ì•„ë‹ˆê¸°ì—, íŒŒë¼ë¯¸í„° ê°œìˆ˜ ë˜í•œ ì¤„ì¼ ìˆ˜ ìˆë‹¤.

ì•„ë˜ëŠ” (32, 32, 3) ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„, ê°œì™€ ê³ ì–‘ì´ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë‹¨ìˆœí•œ ì˜ˆì œì´ë‹¤.
<pre>
<code>
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

input = layers.Input(shape=(32, 32, 3)) # (32, 32) í¬ê¸°ì˜ ì´ë¯¸ì§€ (3ì€ RGB)
hidden = layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu')(input)
fc_layer = layers.Flatten()(hidden)
fc_layer = layers.Dense(32, activation='relu')(fc_layer)
output = layers.Dense(2, activation='softmax')(fc_layer) # ë¶„ë¥˜ë¥¼ ìœ„í•´ softmax ì‚¬ìš©

model = keras.Model(inputs=input, outputs=output)
</code>
</pre>




</br></br>
# 3. RNN, LSTM, GRU (ìˆœí™˜ì‹ ê²½ë§)

* ìì—°ì–´, ì£¼ì‹ ë“± ìˆœì„œê°€ ìˆëŠ” ì—°ì†ì ì¸ ì‹œê³„ì—´ ë°ì´í„° í•™ìŠµì— ì í•©í•œ ëª¨ë¸ì´ë‹¤.
* ì‰½ê²Œ D<sub>t-1</sub>ëŠ” D<sub>t</sub>ì— ì˜í–¥ì„ ì£¼ê¸° ë•Œë¬¸ì— ì´ë¥¼ ë°˜ì˜í•œ êµ¬ì¡°ê°€ ìˆœí™˜ì‹ ê²½ë§ì´ë‹¤. 

<img src="https://user-images.githubusercontent.com/87812424/137648897-85e9d5e0-bd6b-4474-9418-b721bdcc3542.jpg" width="70%" height="70%"/>


## RNN
<img src="https://user-images.githubusercontent.com/87812424/137648847-8dc6a6de-2296-4956-9dd0-d3668e0322f8.png" width="60%" height="60%"/>

* h<sub>t</sub> = tanh(W<sub>x</sub>x<sub>t</sub> + W<sub>h</sub>h<sub>t-1</sub> + bais)
* Shape ì˜ˆì‹œ ë° ì„¤ëª…</br>
  x : (i, j) , Input ë°ì´í„°ë¡œ mì€ timeStamp ìˆ˜, nì€ ê° stepì— ë“¤ì–´ê°ˆ Feature ìˆ˜</br>
  W<sub>x</sub> : (j, n), í•™ìŠµ ê°€ëŠ¥í•œ Weight </br>
  W<sub>h</sub> : (n, n), í•™ìŠµ ê°€ëŠ¥í•œ Weight </br>
  bais : (n, ), í¸í–¥
* ìœ„ ìˆ˜ì‹ê³¼ ê°™ì´ í˜„ì¬ì˜ ê²°ê³¼(hidden == ouput)ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•´ ì´ì „ ê²°ê³¼ë¥¼ ì‚¬ìš©í•œë‹¤.

<pre>
<code>
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

input = layers.Input(shape=(12, 32)) # (12, 5) ê³¼ê±°12ê°œ, ê°ê° 5ê°œì˜ Featureë¥¼ ê°€ì§„ ë°ì´í„° 
rnn = layers.SimpleRNN(32)(input) # (32, )
output = layers.Dense(1)(rnn) # ë¯¸ë˜ 1ê°œ ì˜ˆì¸¡

model = keras.Model(inputs=input, outputs=output)
</code>
</pre>


## LSTM

* ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œ(the problem of Long-Term Dependencies) </br>
  - ì˜ˆì¸¡ì˜ ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ê°€ ì‹œì ì˜ ì•ìª½ì— ì¡´ì¬í•  ìˆ˜ ìˆë‹¤.
  - RNNì€ ì¶©ë¶„í•œ ê¸°ì–µëŠ¥ë ¥ì„ ê°€ì§€ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì—, ê¸´ Sequnceì—ì„œ ì—‰ëš±í•œ ê²°ê³¼ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆë‹¤.

<img src="https://user-images.githubusercontent.com/87812424/137650007-4e53043a-cb56-408b-aa63-20e99f5dd2bf.png" width="60%" height="60%"/>

* Input Gate</br>
  ![input](https://user-images.githubusercontent.com/87812424/137650844-3044e6b3-bdab-406f-9720-b1e196bf824e.png)
  - x<sub>t</sub>ë¥¼ ë¬´ì¡°ê±´ì  ìˆ˜ìš©ì´ ì•„ë‹ˆë¼ ì ì ˆíˆ ì„ íƒí•˜ëŠ” ì—­í• 
* Output Gate</br>
  ![out](https://user-images.githubusercontent.com/87812424/137650883-80e91112-6b45-48da-82fe-05d7798c554c.png)
  - Next Timestepì— í˜„ì¬ì˜ ì¶œë ¥ì´ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ ì¡°ì •í•˜ëŠ” ì—­í• 
* Forget Gate</br>
  ![forget](https://user-images.githubusercontent.com/87812424/137650889-632d81a4-398b-4e81-8401-8fee2c2bb3ca.png)
  - C<sub>t-1</sub>ì˜ ê¸°ì–µ ì¤‘ì—ì„œ ë¶ˆí•„ìš”í•œ ê¸°ì–µì„ ìŠê²Œ í•´ì£¼ëŠ” ì—­í• 

<pre>
<code>
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

input = layers.Input(shape=(12, 32)) # (12, 5) ê³¼ê±°12ê°œ, ê°ê° 5ê°œì˜ Featureë¥¼ ê°€ì§„ ë°ì´í„° 
rnn = layers.LSTM(32)(input) # (32, )
output = layers.Dense(1)(rnn) # ë¯¸ë˜ 1ê°œ ì˜ˆì¸¡

model = keras.Model(inputs=input, outputs=output)
</code>
</pre>


## GRU

* LSTMì˜ ì¥ê¸°ì˜ì¡´ì„±ë¬¸ì œì— ëŒ€í•œ í•´ê²°ì±…ì„ ìœ ì§€í•˜ë©´ì„œ, Hidden Stateë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê³„ì‚°ëŸ‰ì„ ì¤„ì´ë©´ì„œ, ì„±ëŠ¥ì€ LSTMê³¼ ìœ ì‚¬í•œ ëª¨ë¸

<img src="https://user-images.githubusercontent.com/87812424/137651233-51fc4cf1-4494-4fb4-8e02-b576b9122c73.png" width="60%" height="60%"/>

* Reset Gate </br>
  <img src="https://user-images.githubusercontent.com/87812424/137651583-aa3c7406-b863-41e0-8f9b-999c0f89fa3d.png" width="20%" height="20%"/>
  - ì´ì „ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ìŠì–´ì•¼í•˜ëŠ”ì§€ ê²°ì •í•˜ëŠ” ì—­í• 
* Update Gate </br>
  <img src="https://user-images.githubusercontent.com/87812424/137651591-cf4ab0f3-993b-4f40-b0cb-ce909436be5c.png" width="20%" height="20%"/>
  - ì´ì „ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ í†µê³¼ì‹œí‚¬ì§€ ê²°ì •í•˜ëŠ” ì—­í• 

<pre>
<code>
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

input = layers.Input(shape=(12, 32)) # (12, 5) ê³¼ê±°12ê°œ, ê°ê° 5ê°œì˜ Featureë¥¼ ê°€ì§„ ë°ì´í„° 
rnn = layers.GRU(32)(input) # (32, )
output = layers.Dense(1)(rnn) # ë¯¸ë˜ 1ê°œ ì˜ˆì¸¡

model = keras.Model(inputs=input, outputs=output)
</code>
</pre>

## LSTM(GRU) + Attention

* Query, Key, Valueë¥¼ ì¤‘ì ìœ¼ë¡œ ì•„ë˜ URL ì°¸ì¡°
  - https://wikidocs.net/22893




</br></br>
# 4. GCN (ê·¸ë˜í”„ì»¨ë³¼ë£¨ì…˜ì‹ ê²½ë§, Convolution Neural Network)

* ì†Œì…œë„¤íŠ¸ì›Œí¬, êµí†µì •ë³´(Link, Segment) ë“±ê³¼ ê°™ì´ ìœ í¬ë¦¬ë“œ ì¢Œí‘œê³„ì— í‘œí˜„í•˜ê¸° ì–´ë ¤ìš´ ë°ì´í„°ë¥¼ Graph êµ¬ì¡°ë¡œ í‘œí˜„í•˜ì—¬ í•™ìŠµ
* ê° ë…¸ë“œê°„ì˜ ê´€ê³„ë¥¼ ì—°ê´€ì§€ì–´ ì‹ ë¢°ë„ ë†’ì€ ê´€ê³„ ë°ì´í„°ë¥¼ ë„ì¶œ í•  ìˆ˜ ìˆë‹¤.
* ìœ„ì™€ ê°™ì€ GrahpíŠ¹ì§•ê³¼ Convolutionì„ ê²°í•©í•œ ê²ƒì´ GCNì´ë‹¤.

<img src="https://user-images.githubusercontent.com/87812424/137660923-9b8bdf98-2d9a-4409-bb40-e8acf5c52f83.png" width="50%" height="50%"/>

<img src="https://user-images.githubusercontent.com/87812424/137658474-8d9f4438-af2b-4160-8aab-dd6742614fa5.PNG" width="50%" height="50%"/>

### ğ‘“(ğ»<sub>ğ‘–</sub>, ğ´)=ğœ(ğ·<sup>âˆ’1</sup>ğ´ğ»<sub>ğ‘–</sub>ğ‘Š<sub>ğ‘–</sub>)
* D: Nodeì˜ ì—°ê²° ìˆ˜ê°€ ë§ì€ Nodeì¼ìˆ˜ë¡ ê°’ì´ ê°’ì´ ì»¤ì§€ëŠ” í˜„ìƒì„ ë°©ì§€í•˜ê¸° ìœ„í•˜ì—¬, D<sup>-1</sup> Matrixë¥¼ ê³±í•´ì¤€ë‹¤.
* A: ì¸ì ‘í–‰ë ¬ë¡œ ê° Node ì—°ê²°ì •ë³´(Graph)ë¥¼ ë‹´ì€ Matrix   
* H: ê° Nodeë³„ íŠ¹ì§• ë°ì´í„°ë¥¼  Matrix
* W: í•™ìŠµ Weight

<pre>
<code>
from keras import activations, initializers, constraints
from keras import regularizers
from keras.engine import Layer
import keras.backend as K


class GCN(Layer):
    def __init__(self, units, support=1,
                 activation=None,
                 use_bias=True,
                 kernel_initializer='glorot_uniform',
                 bias_initializer='zeros',
                 kernel_regularizer=None,
                 bias_regularizer=None,
                 activity_regularizer=None,
                 kernel_constraint=None,
                 bias_constraint=None,
                 **kwargs):
        if 'input_shape' not in kwargs and 'input_dim' in kwargs:
            kwargs['input_shape'] = (kwargs.pop('input_dim'),)
        super(GCN, self).__init__(**kwargs)
        self.units = units
        self.activation = activations.get(activation)
        self.use_bias = use_bias
        self.kernel_initializer = initializers.get(kernel_initializer)
        self.bias_initializer = initializers.get(bias_initializer)
        self.kernel_regularizer = regularizers.get(kernel_regularizer)
        self.bias_regularizer = regularizers.get(bias_regularizer)
        self.activity_regularizer = regularizers.get(activity_regularizer)
        self.kernel_constraint = constraints.get(kernel_constraint)
        self.bias_constraint = constraints.get(bias_constraint)
        self.supports_masking = True

        self.support = support
        assert support >= 1

    def compute_output_shape(self, input_shapes):
        features_shape = input_shapes[0]
        output_shape = (features_shape[0], self.units)
        return output_shape  # (batch_size, output_dim)

    def build(self, input_shapes):
        features_shape = input_shapes[0]
        assert len(features_shape) == 2
        input_dim = features_shape[1]

        self.kernel = self.add_weight(shape=(input_dim * self.support,
                                             self.units),
                                      initializer=self.kernel_initializer,
                                      name='kernel',
                                      regularizer=self.kernel_regularizer,
                                      constraint=self.kernel_constraint)
        if self.use_bias:
            self.bias = self.add_weight(shape=(self.units,),
                                        initializer=self.bias_initializer,
                                        name='bias',
                                        regularizer=self.bias_regularizer,
                                        constraint=self.bias_constraint)
        else:
            self.bias = None
        self.built = True

    def call(self, inputs, mask=None):
        D, A, H = inputs

        output = K.dot(D, A)
        output = K.dot(output, H)
        output = K.dot(output, self.kernel)

        if self.use_bias:
            output += self.bias
        return self.activation(output)

    def get_config(self):
        config = {'units': self.units,
                  'support': self.support,
                  'activation': activations.serialize(self.activation),
                  'use_bias': self.use_bias,
                  'kernel_initializer': initializers.serialize(
                      self.kernel_initializer),
                  'bias_initializer': initializers.serialize(
                      self.bias_initializer),
                  'kernel_regularizer': regularizers.serialize(
                      self.kernel_regularizer),
                  'bias_regularizer': regularizers.serialize(
                      self.bias_regularizer),
                  'activity_regularizer': regularizers.serialize(
                      self.activity_regularizer),
                  'kernel_constraint': constraints.serialize(
                      self.kernel_constraint),
                  'bias_constraint': constraints.serialize(self.bias_constraint)
        }

        base_config = super(GCN, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))
</code>
</pre>

